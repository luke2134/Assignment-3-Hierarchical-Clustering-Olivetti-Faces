{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF6yBWO0jZc8U1srsr44Fl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luke2134/Assignment-3-Hierarchical-Clustering-Olivetti-Faces/blob/main/olivetti_faces_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 3: Hierarchical Clustering**"
      ],
      "metadata": {
        "id": "5HZDWrBWSsY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Retrieve and Load the Olivetti Faces Dataset**"
      ],
      "metadata": {
        "id": "zP7Y_lKUSw9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXSI30TqSoL_",
        "outputId": "6f60eb2d-93a6-4975-d554-828542a6a653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olivetti Faces dataset loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "# Fetch the Olivetti Faces dataset, shuffle the data for randomness, and set a random state for reproducibility\n",
        "faces_data = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
        "# Assign the image data to 'X' and the target labels (person IDs) to 'y'\n",
        "X, y = faces_data.data, faces_data.target\n",
        "\n",
        "# The following code had been added after the presentation to confirming the dataset has been loaded successfully:\n",
        "# Display a message confirming the dataset has been loaded successfully\n",
        "print(\"Olivetti Faces dataset loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Split the Dataset using Stratified Sampling**"
      ],
      "metadata": {
        "id": "0DknQxe5SzzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into training (60%) and temporary sets (40%) using stratified sampling\n",
        "# to ensure each person is represented equally across the splits\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
        "# Further split the temporary set into validation (20%) and test sets (20%),\n",
        "# again using stratified sampling to ensure equal representation\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# The following code had been added after the presentation to confirm the dataset split has been completed :\n",
        "# Display a message confirming the dataset split has been completed\n",
        "print(\"Dataset split into training, validation, and test sets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDdX1oVdS5Y3",
        "outputId": "23380e92-2753-4842-fd2b-aa7a2f367b29"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split into training, validation, and test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Train a Classifier using k-fold Cross-Validation**"
      ],
      "metadata": {
        "id": "pSakQ8qWS1Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize an SVC classifier with a linear kernel\n",
        "clf = SVC(kernel='linear')\n",
        "\n",
        "# Perform 5-fold cross-validation on the training set to evaluate the classifier's performance\n",
        "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "\n",
        "# Print the average accuracy across the 5 folds to assess how well the classifier performs on the dataset\n",
        "print(\"CV accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFfiNHp0S52s",
        "outputId": "292035eb-e96a-4871-fdce-7681f0a4660d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV accuracy: 0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Apply Hierarchical Clustering**"
      ],
      "metadata": {
        "id": "U3dBtw9sS1LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Apply Agglomerative Clustering with Euclidean distance and the Ward linkage method for clustering\n",
        "# Euclidean Distance:\n",
        "ahc_euclidean = AgglomerativeClustering(n_clusters=40, metric='euclidean', linkage='ward')\n",
        "# Fit the model to the training data and obtain the cluster labels\n",
        "clusters_euclidean = ahc_euclidean.fit_predict(X_train)"
      ],
      "metadata": {
        "id": "9avKv6XKS6cl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Agglomerative Clustering with Minkowski distance and the Complete linkage method for clustering\n",
        "# For Minkowski Distance:\n",
        "ahc_minkowski = AgglomerativeClustering(n_clusters=40, metric='minkowski', linkage='complete')\n",
        "# Fit the model to the training data and obtain the cluster labels\n",
        "clusters_minkowski = ahc_minkowski.fit_predict(X_train)\n"
      ],
      "metadata": {
        "id": "ITOGxphkUQEw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Agglomerative Clustering with Cosine similarity and the Average linkage method for clustering\n",
        "# For Cosine Similarity:\n",
        "ahc_cosine = AgglomerativeClustering(n_clusters=40, metric='cosine', linkage='average')\n",
        "# Fit the model to the training data and obtain the cluster labels\n",
        "clusters_cosine = ahc_cosine.fit_predict(X_train)\n",
        "\n",
        "# Display a message confirming clustering has been completed with the three distance metrics\n",
        "print(\"Hierarchical clustering applied using Euclidean, Minkowski, and Cosine metrics.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id1lHFGuUP5-",
        "outputId": "d9fa0470-50b3-43b6-8ce5-7fe7cc0e83e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hierarchical clustering applied using Euclidean, Minkowski, and Cosine metrics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Use Silhouette Score to Choose Number of Clusters**"
      ],
      "metadata": {
        "id": "d6NvhPkIS1Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Calculate the silhouette score for the clusters obtained using Euclidean distance\n",
        "score_euclidean = silhouette_score(X_train, clusters_euclidean, metric='euclidean')\n",
        "\n",
        "# Calculate the silhouette score for the clusters obtained using Minkowski distance\n",
        "score_minkowski = silhouette_score(X_train, clusters_minkowski, metric='minkowski')\n",
        "\n",
        "# Calculate the silhouette score for the clusters obtained using Cosine similarity\n",
        "score_cosine = silhouette_score(X_train, clusters_cosine, metric='cosine')\n",
        "\n",
        "# Print the silhouette scores for each clustering approach to compare their performance\n",
        "print(\"Silhouette Score - Euclidean:\", score_euclidean)\n",
        "print(\"Silhouette Score - Minkowski:\", score_minkowski)\n",
        "print(\"Silhouette Score - Cosine:\", score_cosine)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzE6Ben_TBbc",
        "outputId": "68c6178d-6fd4-4b65-d0d0-703a4ef609b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score - Euclidean: 0.15845941\n",
            "Silhouette Score - Minkowski: 0.1462153283677593\n",
            "Silhouette Score - Cosine: 0.19488618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Train a Classifier Using Reduced Dimensionality**"
      ],
      "metadata": {
        "id": "ULzHBrbHTBvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform 5-fold cross-validation on the clustered data using the Euclidean clusters as the feature set\n",
        "# Here we reshape the clusters_euclidean array because cross_val_score expects the input as 2D\n",
        "cv_scores_cluster = cross_val_score(clf, clusters_euclidean.reshape(-1, 1), y_train, cv=5)\n",
        "\n",
        "# Print the average accuracy across the 5 folds for the classifier trained on the reduced feature set (clusters)\n",
        "print(\"CV accuracy after clustering:\", cv_scores_cluster.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztdKlpdnTFr6",
        "outputId": "fbebe817-f5b4-412a-a0b8-440998d10129"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV accuracy after clustering: 0.3\n"
          ]
        }
      ]
    }
  ]
}